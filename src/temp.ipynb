{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amod/mental_health_counseling_conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = 'KonradSzafer/stackoverflow_python_preprocessed'\n",
    "# dataset_name = 'graycatHCO3/CodeAlpaca-20K-Python'\n",
    "dataset_name = 'glaiveai/glaive-code-assistant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\h4has\\anaconda3\\envs\\rag\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading readme: 100%|██████████| 541/541 [00:00<?, ?B/s] \n",
      "Downloading data: 100%|██████████| 780k/780k [00:00<00:00, 2.04MB/s]\n",
      "Downloading data: 100%|██████████| 90.5k/90.5k [00:00<00:00, 268kB/s]\n",
      "Generating train split: 100%|██████████| 4777/4777 [00:00<00:00, 77436.35 examples/s]\n",
      "Generating test split: 100%|██████████| 548/548 [00:00<00:00, 182187.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'completion'],\n",
      "        num_rows: 4777\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'completion'],\n",
      "        num_rows: 548\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset(dataset_name)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'completion'],\n",
      "    num_rows: 4777\n",
      "})\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'])\n",
    "print(type(dataset['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = [data for data in dataset['train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4777\n"
     ]
    }
   ],
   "source": [
    "print(len(data_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'Write a reusuable function in Python that takes two string variables and returns the longest string.\\n', 'completion': 'def longest_string(str1, str2):\\n    if len(str1) > len(str2):\\n        return str1\\n    else:\\n        return str2'}\n"
     ]
    }
   ],
   "source": [
    "for data in dataset['train']:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = 'meta-llama/Meta-Llama-3.1-8B-Instruct'\n",
    "# model = 't5-small'\n",
    "model = 'flan-t5-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import LlamaTokenizer, Llama\n",
    "\n",
    "# tokenizer = LlamaTokenizer.from_pretrained(model)\n",
    "# model = LlamaForCausalLM.from_pretrained(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"What is mental health?\"\n",
    "# inputs = tokenizer(query, return_tensors=\"pt\")\n",
    "# print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\h4has\\anaconda3\\envs\\rag\\lib\\site-packages\\transformers\\generation\\utils.py:1259: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,  8477, 18154,     3,   390,  2869,    54,   199,    25,  1591,\n",
      "             6,    36,   213,    25,    33,     3,     6,  4839,    11, 16363]])\n",
      "Mindfulness based practices can help you ground, be where you are, relax and regulate\n"
     ]
    }
   ],
   "source": [
    "\n",
    "outputs = model.generate(**inputs)\n",
    "print(outputs)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(data_dict)\n",
    "# df.head(3)\n",
    "# df.to_csv('data/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('ml.json')\n",
    "print(len(df))\n",
    "df.head(3)\n",
    "df.to_csv('data/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question    0\n",
       "answer      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retreiving\n",
    "# Indexing - Elasticsearch, TF-IDF \n",
    "# Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import minisearch\n",
    "ms = minisearch.Index(\n",
    "    text_fields=[\"question\", \"answer\"],\n",
    "    keyword_fields=[\"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minisearch.Index at 0x21747c06760>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create index - minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What’s the trade-off between bias and variance?',\n",
       " 'answer': 'Bias is error due to erroneous or overly simplistic assumptions in the learning algorithm, leading to underfitting and poor generalization. Variance is error due to too much complexity in the learning algorithm, leading to overfitting and high sensitivity to training data. The bias-variance decomposition breaks down learning error into bias, variance, and irreducible error. Increasing model complexity reduces bias but increases variance. The goal is to find a balance to minimize total error.'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minisearch.Index at 0x21747c06760>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms.fit(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "search using index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = 'multi-qa-MiniLM-L6-cos-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(embedding_model)\n",
    "embedding =model.encode('How to sort a dictionary in python?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "<class 'numpy.ndarray'>\n",
      "[0.012473829090595245, -0.03423825651407242, 0.02401108294725418, 0.062352072447538376, 0.012287676334381104, 0.04485062137246132, -0.01238344144076109, 0.00038591978955082595, -0.005918867886066437, -0.047173574566841125, 0.01976957358419895, -0.01812436431646347, 0.028216853737831116, 0.005306615494191647, -0.05160516873002052, -0.0032452542800456285, -0.02006971277296543, -0.021828610450029373, 0.06239515170454979, 0.02873624488711357, -0.06761425733566284, -0.028046200051903725, -0.033938150852918625, -0.027862848713994026, 0.022949669510126114, 0.0379955880343914, -0.0070092580281198025, 0.03170578181743622, 0.03905501216650009, -0.05780861899256706, -0.012664245441555977, 0.037202443927526474, -0.0290141012519598, 0.018525587394833565, 1.3947289971838472e-06, -0.033404428511857986, 0.01877940259873867, -0.03210664168000221, 0.044481415301561356, -0.020577382296323776, 0.05126888304948807, 0.039636582136154175, -0.012339640408754349, -0.02918345294892788, -0.0861273929476738, -0.07636485993862152, 0.014083052054047585, -0.014584751799702644, 0.09644237905740738, 0.001482333755120635, -0.026196245104074478, -0.027589473873376846, -0.022838493809103966, 0.005842892453074455, -0.00624376256018877, -0.010989120230078697, 0.03059711493551731, 0.04300756752490997, -0.056967396289110184, -0.005463059060275555, -0.004092145245522261, -0.03199077397584915, -0.015551282092928886, 0.05770464614033699, 0.005838370881974697, -0.0015145651996135712, -0.024800922721624374, -0.005966524127870798, -0.0096998680382967, 0.010101569816470146, 0.031010158360004425, -0.004714943468570709, 0.003221676917746663, 0.01299415435642004, -0.0069194212555885315, 0.0028824799228459597, -0.006570310797542334, -0.012020325288176537, 0.05422396585345268, -0.0030047569889575243, 0.04823607578873634, 0.02417062595486641, -0.004665958229452372, 0.03446107730269432, -0.017645560204982758, 0.033895596861839294, -0.021526740863919258, -0.04565095528960228, -0.04615660384297371, -0.012289938516914845, 0.021117765456438065, -0.006881042383611202, -0.022963156923651695, 0.015001612715423107, 0.0422462560236454, -0.041436392813920975, 0.03520860895514488, -0.020366648212075233, 0.005722413305193186, 0.013283669017255306, -0.07004576921463013, -0.06788771599531174, 0.01389344036579132, -0.03251810744404793, 0.010594607330858707, 0.031067075207829475, 0.008468505926430225, 0.03692508116364479, -0.04761085659265518, 0.02664797380566597, 0.013110495172441006, -0.0050225527957081795, 0.04815679043531418, -0.05911026522517204, 0.025504766032099724, 0.015466167591512203, 0.0006317261722870171, -0.0023662601597607136, -0.025109902024269104, 0.00779629684984684, -0.016798295080661774, 0.016816988587379456, 0.09817653894424438, 0.035518862307071686, -0.04467374458909035, 0.000983659876510501, 0.051173411309719086, -0.012426039204001427, 0.017493071034550667, 0.096539705991745, 0.012405931018292904, 0.004893942270427942, 0.05615914985537529, -0.008492323569953442, -0.024013282731175423, 0.012736622244119644, 0.03880887106060982, -0.05847896635532379, 0.06871567666530609, 0.0059562926180660725, 0.015092145651578903, 0.04209732636809349, -0.0066588702611625195, -0.008343786001205444, -0.02281937375664711, 0.009842226281762123, 0.03901827707886696, -0.058366693556308746, 0.01649269461631775, -0.04691071808338165, -0.04927084594964981, 0.016521573066711426, -0.023645170032978058, -0.0011179317953065038, 0.028676200658082962, -0.022181672975420952, -0.03680466488003731, -0.0926717147231102, 0.03498121351003647, 0.0056349728256464005, -0.005509943701326847, -0.024858741089701653, 0.008633855730295181, -0.09595389664173126, -0.06094988435506821, -0.027220813557505608, -0.06428900361061096, -0.041919466108083725, -0.07885368913412094, 0.011478756554424763, -0.03777727857232094, -0.005179120693355799, 0.029966743662953377, 0.004941536113619804, 0.020721042528748512, 0.008013001643121243, 0.008437251672148705, -0.09094791114330292, -0.08957034349441528, -0.010743041522800922, -0.01085876114666462, 0.01639637164771557, -0.0357995368540287, 0.011173486709594727, 0.07288923114538193, -0.022683339193463326, 0.06874501705169678, 0.009969505481421947, 0.027093611657619476, -0.02675618976354599, 0.0026172322686761618, -0.043481115251779556, 0.0741998478770256, 0.037930652499198914, -0.02651643194258213, -0.03854038566350937, -0.019857926294207573, 0.018990976735949516, 0.025431612506508827, -0.02508576214313507, -0.06295442581176758, -0.0724794790148735, -0.04298528656363487, 0.06890098750591278, -0.02919057570397854, -0.0019764245953410864, -0.005493640433996916, 0.034383781254291534, -0.03291339799761772, 0.001842422760091722, 0.007483691442757845, 0.022175343707203865, -0.05646246299147606, -0.018197735771536827, -0.034402742981910706, 0.01831384189426899, -0.016932351514697075, -0.051985591650009155, 0.06199834123253822, 0.025268595665693283, 0.023246537894010544, 0.029491441324353218, -0.02650829777121544, -0.018111854791641235, 0.04314521700143814, -0.0013538118219003081, -0.023857399821281433, 0.033964965492486954, -0.06269896030426025, 0.0006711354944854975, -0.03594370186328888, 0.06649862229824066, 0.029285648837685585, -6.048028080840595e-05, 0.026929514482617378, -0.038078006356954575, 0.011385553516447544, 0.005099565256386995, -0.018079102039337158, 0.015719547867774963, 0.046551235020160675, 0.07098548859357834, 0.028057221323251724, 0.02924463339149952, -0.00513543700799346, 0.07881095260381699, 0.04882925748825073, -0.010797041468322277, -0.012602860108017921, 0.0533038005232811, -0.03307352587580681, -0.046779897063970566, 0.028247298672795296, -0.030411850661039352, 0.004145963117480278, -0.03290865942835808, 0.03007483296096325, -0.04893847927451134, 0.01726476289331913, -0.03098907694220543, 0.10432260483503342, -0.029209179803729057, 0.01521613635122776, -0.011896360665559769, 0.015024668537080288, 0.01871713437139988, -0.02328975684940815, 0.020455945283174515, -0.04082706943154335, 0.04324668273329735, -0.011309360153973103, -0.0010403566993772984, 0.02616894245147705, -0.00604694988578558, -0.00015369344328064471, 0.05429244041442871, -0.007143102586269379, -0.034634023904800415, 0.0030959139112383127, -0.0003141712804790586, -0.013129552826285362, 0.0024863125290721655, -0.01898549683392048, -0.0007991960155777633, 0.02549571730196476, 0.04906882345676422, -0.029425008222460747, -0.023211972787976265, 0.03886622190475464, -0.0004906246904283762, -0.0400085411965847, -0.014131165109574795, 0.021360520273447037, -0.026529835537075996, 0.00021703277889173478, 0.03111409954726696, 0.04394538328051567, 0.019307082518935204, 0.044098690152168274, 0.017703821882605553, 0.06792055070400238, -0.009214857593178749, 0.0312950536608696, -0.013434539549052715, 0.023685911670327187, 0.016443492844700813, 0.05644911155104637, 0.004397442098706961, -0.06026177108287811, 0.044417716562747955, 0.03901779651641846, 0.010062286630272865, -0.03173038735985756, -0.025979945436120033, -0.0756540521979332, -0.00012126329238526523, -0.043786779046058655, -0.0035405061207711697, -0.018744464963674545, 0.012063121423125267, 0.0013842948246747255, 0.014181130565702915, -0.02569006383419037, 0.03601289913058281, 0.06536974012851715, -0.008419300429522991, -0.017400123178958893, -0.023758646100759506, 0.007475084159523249, 0.02219581976532936, 0.0467955619096756, -0.0524870865046978, -0.02361244149506092, -0.020410723984241486, -0.006695664022117853, 0.03218895196914673, -0.027445213869214058, 0.054627563804388046, -0.003658067435026169, 0.012527763843536377, 0.014408069662749767, 0.08286944776773453, -0.017202775925397873, -0.010354803875088692, -0.037636369466781616, -0.010440669022500515, -0.01907488889992237, 0.000511349004227668, 0.039430759847164154, 0.025905760005116463, 0.018357712775468826, 0.060836102813482285, 0.04333695024251938, 0.015249034389853477, 0.011789588257670403, 0.012458382174372673, -0.04859989881515503, 0.054712485522031784, 0.014905392192304134, 0.05004923790693283, 0.061802756041288376, 0.0007227528840303421, 0.013973410241305828, 0.04491208866238594, -0.0018626272212713957, 0.011274688877165318, 0.008214025758206844, -0.07066476345062256, -0.00871908850967884, 0.0018240096978843212, -0.022378386929631233, 0.033548470586538315, 0.011543921194970608, 0.06944160163402557, 0.0311722531914711, 0.02290927991271019, 0.0015672161243855953, -0.0340382419526577, -0.05864979326725006, -0.004196935798972845, 0.005189002491533756, -0.032527726143598557, -0.008133911527693272, -0.030096223577857018, 0.004301035776734352, -0.0061667789705097675, -0.008204186335206032, -0.012939471751451492, 0.05137867480516434, -0.027973832562565804, -0.013742930255830288, 0.029429186135530472, -0.038673773407936096, -0.01922714151442051, -0.08014220744371414, -0.02901158668100834, -0.008825326338410378, 0.031998999416828156, 0.004251765087246895, -0.003141968511044979, 0.005604471080005169, 0.07429328560829163, 0.01705828681588173, -0.003127641975879669, -0.002185230376198888, -0.014232942834496498, 0.021627917885780334, 0.034562818706035614, -0.007979052141308784, 0.036099016666412354, -0.02432657591998577, 0.010970898903906345, 0.02635389380156994, -0.007289531175047159, -0.0019390149973332882, 0.010110524483025074, -0.00033621874172240496, 0.010155347175896168, -0.05025644972920418, -0.0732918530702591, -0.06379397213459015, -0.06594481319189072, -0.019738953560590744, -0.005924212280660868, 0.027701960876584053, 0.042798031121492386, -0.04492028430104256, -0.04170937463641167, 0.0013136470224708319, 0.017932843416929245, 0.09049096703529358, 0.004052008036524057, -0.00492402957752347, 0.030748827382922173, 0.05301670730113983, -0.038150329142808914, 0.02310590259730816, 0.06032567098736763, -0.031316161155700684, -0.059519216418266296, 0.03513074293732643, -0.03485410660505295, -0.09934274107217789, -0.041070356965065, 0.01831134594976902, -0.008798297494649887, 0.01670917682349682, -0.06773365288972855, -0.04032163694500923, 0.062039077281951904, -0.0031137207988649607, -0.06075423210859299, -0.0869748443365097, 0.0726386085152626, 0.05277175083756447, 0.034905556589365005, 0.038001302629709244, 0.027828292921185493, 0.0161310862749815, 0.07328658550977707, -0.032932352274656296, 0.011633218266069889, -0.07256446778774261, 0.014197224751114845, 0.045255836099386215, 0.01130222249776125, 0.039119284600019455, 0.014209643937647343, -0.009255794808268547, -0.05715758353471756, -0.011710221879184246, -0.017068294808268547, 0.014164388179779053, -0.014991529285907745, 0.03735964000225067, -0.09277214854955673, -0.015708116814494133, -0.03943011164665222, -0.06623133271932602, 0.022874806076288223, 0.0504935160279274, 0.03712688013911247, -0.05083322897553444, -0.10257474333047867, -0.03326556831598282, 0.009723502211272717, -0.004387916997075081, -0.01276698149740696, 0.06829045712947845, -0.03751938045024872, -0.0028001577593386173, -0.007626048289239407, -0.013203300535678864, 0.015655197203159332, 0.008423405699431896, -0.006142676342278719, -0.004323055036365986, 0.06362339854240417, 0.038754455745220184, -0.003920792136341333, 0.03540968894958496, -0.004800275433808565, -0.015914760529994965, 0.005798771046102047, -0.04567102715373039, 0.008218548260629177, 0.0039072963409125805, -0.002676029922440648, -0.044825486838817596, -0.015282075852155685, -0.009095253422856331, 0.1137733906507492, -0.046118784695863724, -0.03861360251903534, -0.030541162937879562, -0.020525150001049042, -0.015165535733103752, -0.024810748174786568, 0.07915335893630981, 0.01178767904639244, 0.026135075837373734, 0.019987473264336586, 0.02676246128976345, 0.031172841787338257, 0.03524715453386307, -0.0648532435297966, 0.017897292971611023, 0.017691416665911674, 0.03192591294646263, 0.025570185855031013, 0.021362708881497383, -0.010878766886889935, 0.021509302780032158, 0.008769338019192219, 0.01659037172794342, 0.02805541642010212, -0.016159985214471817, 0.049589283764362335, 0.007225049659609795, 0.0735282450914383, -0.0022153337486088276, -0.03065667487680912, -0.013601922430098057, 0.010926089249551296, 0.025069717317819595, -0.06212905794382095, -0.050170302391052246, -0.006939902901649475, -0.048254504799842834, 0.06375890970230103, -0.003747382201254368, -0.021769072860479355, -0.021099688485264778, 0.008476666174829006, -0.0035030043218284845, -4.494309061143115e-33, -0.007178673055022955, -0.04507451876997948, -0.00473882956430316, -0.04379180446267128, 0.033381760120391846, 0.05029638111591339, 0.03941481187939644, 0.017578043043613434, -0.017480306327342987, -0.04265233129262924, -0.022822441533207893, 0.018580080941319466, -0.0010070099961012602, -0.06014379858970642, -0.0304288100451231, -0.002693673362955451, -0.07291021943092346, -0.022476404905319214, 0.0373334065079689, -0.05051586031913757, 0.011002016253769398, 0.021679431200027466, 0.053321242332458496, 0.05881046876311302, 0.0013400125317275524, 0.027044285088777542, -0.00022129049466457218, 0.016426492482423782, -0.012206042185425758, -0.02090553566813469, 0.0025338807608932257, -0.008154950104653835, 0.014316168613731861, -0.029881376773118973, 0.03197512775659561, -0.001836357288993895, 0.05223584175109863, -0.020191827788949013, -0.07817122340202332, -0.03278857469558716, 0.04993675276637077, 0.021737493574619293, 0.011172330006957054, 0.009779881685972214, -0.027871739119291306, -0.013944649137556553, 0.017360564321279526, -0.02348080277442932, -0.03864510729908943, 0.03454611077904701, 0.029245650395751, 0.004956527147442102, 0.01680878736078739, -0.07482067495584488, 0.03687320649623871, -0.029881268739700317, -0.03326006978750229, -0.06063223257660866, 0.00332554429769516, 0.05432356148958206, 0.00626920023933053, 0.05829649418592453, -0.019289076328277588, -0.014622937887907028, -0.07618942856788635, 0.007051656022667885, 0.034024376422166824, 0.03054998070001602, 0.07078950852155685, -0.07112842798233032, -0.022899171337485313, -0.00021973812545184046, -0.0846700444817543, 0.003257542150095105, 0.005147166084498167, 0.008405381813645363, 0.005985037889331579, 0.05209320783615112, 0.009104429744184017, -0.004462449811398983, -0.008938881568610668, -0.02240375056862831, 0.01494862325489521, 0.015080738812685013, -0.008708667010068893, 0.016201572492718697, -0.005851060152053833, 0.032111939042806625, 0.03031109645962715, -0.06077553704380989, -0.12636128067970276, -0.026925114914774895, -0.017539411783218384, -0.010982983745634556, 0.0016379712615162134, 0.05434100329875946, -0.04145774245262146, 0.019586527720093727, -0.01874992996454239, -0.014829098246991634, 0.020880650728940964, -0.0027486588805913925, 0.0028216736391186714, 0.01878407970070839, 0.00714522460475564, 0.01907419227063656, -0.07755445688962936, 0.019415417686104774, -0.018620705232024193, -0.04513907805085182, 0.02148248627781868, -0.027809690684080124, -0.03314037248492241, 0.024173753336071968, -0.031966615468263626, -0.007671371102333069, 0.017648989334702492, -0.017874810844659805, 0.03971230238676071, -0.02779986895620823, -0.001883160788565874, 0.03711538761854172, -0.023516003042459488, -0.03853880986571312, -0.004601517226547003, 0.01720474101603031, -0.003562824334949255, -0.04108789563179016, -0.02383887581527233, 0.05558323487639427, -0.038477737456560135, -0.031171943992376328, 2.1733643507104716e-07, -0.014547320082783699, 0.0776023268699646, -0.03615638241171837, 0.07407955080270767, -0.002334826858714223, 0.025516027584671974, -0.012207397259771824, -0.017924543470144272, -0.007481895387172699, -0.05103236436843872, 0.04529180750250816, 0.028779080137610435, -0.026267778128385544, -0.011769833974540234, 0.018831174820661545, -0.01320224441587925, -0.020519910380244255, -0.012385839596390724, 0.04094360023736954, -0.058459099382162094, 0.05586528778076172, -0.00672185281291604, -0.012502958066761494, -0.027271075174212456, -0.07159917056560516, 0.0046140574850142, -0.021396705880761147, -0.053530070930719376, 0.03479209914803505, -0.052476104348897934, 0.010946199297904968, -0.06407547742128372, 0.026000984013080597, 0.04976680502295494, 0.004216704051941633, -0.04285828769207001, 0.05428009107708931, 0.009157445281744003, -0.046495698392391205, 0.010624857619404793, 0.030537009239196777, 0.010982702486217022, 0.0038497820496559143, -0.005534672643989325, -0.02833995781838894, 0.059994447976350784, 0.02655978873372078, -0.022865094244480133, -0.02547888457775116, 0.02090318128466606, -0.040940847247838974, 0.016884740442037582, -0.017982948571443558, 0.0335238091647625, 0.005639998707920313, -0.03762194141745567, -0.00014764390652999282, 0.01876824162900448, -0.021662574261426926, -0.035798076540231705, 0.03972002863883972, -0.0070874434895813465, 0.017948726192116737, 0.00850062258541584, 0.02640482969582081, 0.10712678730487823, 0.02575477957725525, 7.874009304925375e-35, -0.055085062980651855, 0.02892877720296383, 0.0006344615831039846, 0.0182451494038105, -0.006925398949533701, 0.012538325041532516, 0.04066617414355278, -0.01652808114886284, -0.02376713789999485, 0.015294480137526989, 0.033304959535598755]\n"
     ]
    }
   ],
   "source": [
    "print(len(embedding))\n",
    "print(type(embedding))\n",
    "print(embedding.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639\n"
     ]
    }
   ],
   "source": [
    "print(len(data_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector DB SentenceTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentencesDataset\n",
    "\n",
    "model = SentenceTransformer(embedding_model,truncate_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.encode('How to sort a dictionary in python?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What’s the trade-off between bias and variance?',\n",
       " 'answer': 'Bias is error due to erroneous or overly simplistic assumptions in the learning algorithm, leading to underfitting and poor generalization. Variance is error due to too much complexity in the learning algorithm, leading to overfitting and high sensitivity to training data. The bias-variance decomposition breaks down learning error into bias, variance, and irreducible error. Increasing model complexity reduces bias but increases variance. The goal is to find a balance to minimize total error.'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639\n"
     ]
    }
   ],
   "source": [
    "print(len(data_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_data = []\n",
    "for data in data_dict[:10]:\n",
    "    data['answer_vector'] = model.encode(data['answer'])\n",
    "    data['question_vector'] = model.encode(data['question'])\n",
    "    embedded_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What’s the trade-off between bias and variance?', 'answer': 'Bias is error due to erroneous or overly simplistic assumptions in the learning algorithm, leading to underfitting and poor generalization. Variance is error due to too much complexity in the learning algorithm, leading to overfitting and high sensitivity to training data. The bias-variance decomposition breaks down learning error into bias, variance, and irreducible error. Increasing model complexity reduces bias but increases variance. The goal is to find a balance to minimize total error.', 'answer_vector': array([ 3.93690355e-02,  1.68576669e-02,  2.18878947e-02, -1.77346300e-02,\n",
      "        9.37577784e-02, -4.56591864e-04, -1.09980758e-02, -2.95686591e-02,\n",
      "        3.20731215e-02,  1.96286440e-02, -4.71137872e-04,  2.88731828e-02,\n",
      "        6.66112732e-03,  1.17804017e-02, -2.79367971e-03,  7.56513625e-02,\n",
      "       -5.07901087e-02,  4.23743948e-02, -1.05550721e-01, -8.33066702e-02,\n",
      "       -5.01522049e-02, -5.66405170e-02, -9.59390327e-02,  3.75285223e-02,\n",
      "       -1.04970671e-02, -2.66443212e-02, -5.01827709e-02, -1.00539334e-01,\n",
      "       -1.92117132e-02,  2.10128166e-02,  4.81427200e-02, -1.21168932e-02,\n",
      "        8.53633285e-02,  3.47868577e-02, -3.12386565e-02,  1.96525734e-02,\n",
      "       -4.22435887e-02, -2.76782382e-02,  4.11707982e-02,  2.05994528e-02,\n",
      "       -5.23686260e-02,  7.68738165e-02, -6.31918013e-02,  1.39600900e-03,\n",
      "        6.76785316e-03, -1.64283197e-02,  5.04306937e-03, -7.13218451e-02,\n",
      "       -6.14578910e-02, -3.99198756e-02, -4.34841700e-02,  5.10197356e-02,\n",
      "       -2.24604271e-02, -5.59338927e-02, -7.95251355e-02, -2.55392138e-02,\n",
      "        1.88192893e-02,  5.84684275e-02, -8.61750916e-02,  7.65976757e-02,\n",
      "        1.05794936e-01, -7.86285475e-02, -7.48803392e-02, -8.80266074e-03,\n",
      "       -5.33093847e-02, -6.92880750e-02,  4.67453748e-02,  2.19131578e-02,\n",
      "        2.08613146e-02,  3.36350165e-02, -1.19717477e-03,  2.36848965e-02,\n",
      "       -2.20586937e-02,  2.64172219e-02,  7.92682841e-02, -1.81180295e-02,\n",
      "        4.28525209e-02, -9.21187084e-03,  7.00183585e-02,  5.79815218e-03,\n",
      "        1.14129651e-02,  4.25783359e-02,  1.58933960e-02, -1.78770535e-03,\n",
      "        5.98998033e-02, -9.02371481e-02, -7.70951658e-02, -8.07824507e-02,\n",
      "        4.61294316e-02,  6.66628545e-03,  3.48904543e-02, -4.74043787e-02,\n",
      "       -1.13596149e-01,  1.48605168e-01,  9.47473347e-02,  3.46551165e-02,\n",
      "       -6.55073160e-03,  2.59124339e-02,  2.11048443e-02,  3.59639563e-02,\n",
      "        1.09165348e-02, -1.24111017e-02, -5.91708012e-02,  1.05737075e-01,\n",
      "        1.88413784e-02, -2.28728987e-02,  6.38967380e-02, -3.38932537e-02,\n",
      "       -1.53740849e-02, -7.83043876e-02, -4.27661507e-05, -9.44217574e-03,\n",
      "       -8.28666706e-03,  6.65428936e-02, -3.30745168e-02,  2.61937119e-02,\n",
      "        5.25289811e-02,  5.40585890e-02, -1.12384871e-01,  9.21759829e-02,\n",
      "       -4.41128574e-02, -6.00117892e-02, -1.82773322e-02,  6.20259382e-02,\n",
      "        4.45848703e-02, -2.22229306e-02, -6.16370216e-02, -3.53539894e-31],\n",
      "      dtype=float32), 'question_vector': array([ 1.7328983e-02, -1.0363858e-02, -1.8507434e-02,  2.7583191e-02,\n",
      "        7.8534178e-02,  3.4612518e-02,  4.7085851e-02, -1.5687730e-02,\n",
      "        8.5510984e-02,  1.9540764e-02, -1.2864571e-02, -2.1694511e-02,\n",
      "       -2.4722030e-02, -1.1135382e-03,  7.4622154e-02,  9.9184647e-02,\n",
      "       -1.9826095e-03, -1.0174086e-02, -2.9547388e-02,  6.8964306e-03,\n",
      "       -7.3717616e-02, -7.4617110e-02, -1.3171321e-01,  2.1484893e-02,\n",
      "        4.0786766e-02, -3.2582123e-02, -1.7769534e-02, -3.4534529e-02,\n",
      "       -2.5769321e-02, -7.2018062e-03,  5.6837067e-02, -1.0365603e-02,\n",
      "       -1.2821755e-03, -4.6673317e-02, -8.6544000e-02,  1.2464866e-02,\n",
      "       -1.0802983e-02, -6.0274713e-03,  4.3178748e-02,  3.7206542e-02,\n",
      "       -8.3247662e-02,  5.1359277e-02, -7.2048858e-02,  2.5427936e-02,\n",
      "        1.7394872e-02, -3.7778102e-02,  3.9311297e-02, -3.2689532e-03,\n",
      "       -7.8637145e-02, -4.5469948e-03, -4.5367993e-02,  2.4441233e-02,\n",
      "       -2.7697133e-02,  4.0033283e-03, -4.9537346e-02, -1.3056578e-02,\n",
      "       -1.7301986e-02,  3.4161564e-02, -6.0087681e-02,  4.1518711e-02,\n",
      "        8.7218598e-02, -5.1061142e-02, -6.6665590e-02,  8.3726317e-02,\n",
      "       -5.5362001e-02, -9.8488495e-02,  5.5103637e-02,  8.8626994e-03,\n",
      "        5.5980425e-02, -4.8767105e-02, -3.8229495e-02, -1.4873342e-02,\n",
      "       -2.6168481e-03, -1.4714298e-02,  3.2600928e-02, -2.3946166e-02,\n",
      "        6.3351467e-02, -2.5409698e-02,  6.7211300e-02, -5.7621051e-02,\n",
      "       -3.9621522e-03,  2.2827370e-02, -1.8077426e-02, -1.4653365e-02,\n",
      "        1.2456304e-02, -2.8015953e-02, -3.9575834e-02,  2.4542293e-02,\n",
      "        1.1243028e-02, -1.0188333e-02,  2.9048877e-02, -1.3378004e-02,\n",
      "       -4.7674786e-02,  5.0002255e-02,  4.3491799e-02,  2.7183790e-02,\n",
      "       -4.9748752e-02,  8.0934867e-02,  9.4540060e-02,  5.2293755e-02,\n",
      "        4.1236833e-02, -1.1659126e-02, -6.8158098e-02,  7.8159705e-02,\n",
      "        1.0357728e-02, -8.9356698e-02,  4.5718804e-02, -5.7860068e-03,\n",
      "       -3.2245509e-02, -4.3187652e-02, -5.1622774e-02,  1.9131416e-02,\n",
      "       -3.8343016e-02,  5.1749565e-02, -5.1041115e-02,  8.4224213e-03,\n",
      "        7.1376547e-02,  8.4593296e-02,  2.7196066e-02,  9.2075966e-02,\n",
      "       -1.7602939e-02, -6.2709786e-02,  3.5968073e-02,  7.0078694e-03,\n",
      "        3.1621968e-03,  1.0314175e-02, -9.6557112e-03,  1.8538114e-31],\n",
      "      dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "print(embedded_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '7d50c3ad219e', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'GkHNY1cCQQGIGcngnIggvA', 'version': {'number': '8.15.0', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '1a77947f34deddb41af25e6f0ddb8e830159c179', 'build_date': '2024-08-05T10:05:34.233336849Z', 'build_snapshot': False, 'lucene_version': '9.11.1', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "es.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings={\n",
    "    \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "        \"question\": {\"type\": \"text\"},\n",
    "        \"answer\": {\"type\": \"text\"},\n",
    "        \"answer_vector\": {\"type\": \"dense_vector\", \"dims\": 128, \"index\": True, \"similarity\": \"cosine\"},\n",
    "        \"question_vector\": {\"type\": \"dense_vector\", \"dims\": 128, \"index\": True, \"similarity\": \"cosine\"},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "index_name = 'python-qa-index'\n",
    "\n",
    "query='What is the tradeoff between bias and variance?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'python-qa-index'})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.delete(index=index_name,ignore_unavailable=True)\n",
    "es.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = model.encode(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_query = {\n",
    "    \"field\": \"answer_vector\",\n",
    "    \"query_vector\": query_vector,\n",
    "    \"k\": 5,\n",
    "    \"num_candidates\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = es.search(index=index_name, knn=knn_query, size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 11, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 0, 'relation': 'eq'}, 'max_score': None, 'hits': []}})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in embedded_data:\n",
    "    es.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Elasticsearch(['http://localhost:9200'])>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"How to create a dictionary in python?\"\n",
    "query = \"How to sort a dictionary in python?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "results = ms.search(\n",
    "    query=query,\n",
    "    # filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "    # boost_dict=boost,\n",
    "    num_results=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Certainly! In Python, you can sort a dictionary based on its values using the `sorted()` function along with the `items()` method of the dictionary. Let me explain the solution to you.\\n\\nHere\\'s an example code that sorts a dictionary based on its values in ascending order:\\n\\n```python\\ndictionary = {\"a\": 10, \"b\": 3, \"c\": 4, \"d\": 1, \"e\": 5}\\nsorted_dict = dict(sorted(dictionary.items(), key=lambda x: x[1], reverse=False))\\n\\nprint(\"Sorting Dictionary as per the Value:\")\\nprint(\"The Original Dictionary:\", dictionary)\\nprint(\"The Sorted Dictionary:\", sorted_dict)\\n```\\n\\nExplanation:\\n\\n1. We first define a dictionary called `dictionary` with key-value pairs representing some data.\\n\\n2. Then, we use the `sorted()` function to sort the dictionary based on its values. The `items()` method helps to iterate over the key-value pairs of the dictionary.\\n\\n3. The `key` parameter in the `sorted()` function takes a lambda function `lambda x: x[1]`, which specifies that we want to sort based on the values (`x[1]`). The `x` represents each key-value pair in the dictionary.\\n\\n4. Additionally, we set the `reverse` parameter to `False` to sort the dictionary in ascending order. If you want to sort in descending order, you can change it to `True`.\\n\\n5. Finally, we convert the sorted key-value pairs back into a dictionary using the `dict()` constructor and store it in the variable `sorted_dict`.\\n\\n6. We then print the original dictionary and the sorted dictionary to see the results.\\n\\nBy running this code, you will get the sorted dictionary based on its values.',\n",
       " \"To sort a dictionary by its values in Python, you can use the `sorted()` function along with the `items()` method of the dictionary to retrieve the key-value pairs. Then, you can specify the sorting criteria using a lambda function as the `key` parameter. Here's an example code:\\n\\n```python\\ndictionary = {'key1': 1, 'key2': 3, 'key3': 2}\\nsorted_dict = {key: value for key, value in sorted(dictionary.items(), key=lambda item: item[1])}\\n```\\n\\nIn the code above, the `sorted()` function is used to sort the `dictionary.items()` based on the second element of each item (i.e., the values of the dictionary). The lambda function `lambda item: item[1]` specifies that the sorting should be based on the second element (`item[1]`) of each item.\\n\\nThe sorted dictionary is then created using a dictionary comprehension, where each key-value pair from the sorted items is assigned to the `key` and `value` variables, respectively.\\n\\nAfter running this code, the `sorted_dict` variable will contain the sorted dictionary based on the values.\"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = [result['answer'] for result in results]\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a python coder. Provide concise and short python code for the question based on the context.\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{response}\n",
    "If you dont know the answer, just say that you dont know.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Sort a Python dictionary by value',\n",
       " 'answer': 'Why not try this approach. Let us define a dictionary called mydict with the following data:\\nmydict = {\\'carl\\':40,\\n          \\'alan\\':2,\\n          \\'bob\\':1,\\n          \\'danny\\':3}\\n\\nIf one wanted to sort the dictionary by keys, one could do something like:\\nfor key in sorted(mydict.iterkeys()):\\n    print \"%s: %s\" % (key, mydict[key])\\n\\nThis should return the following output:\\nalan: 2\\nbob: 1\\ncarl: 40\\ndanny: 3\\n\\nOn the other hand, if one wanted to sort a dictionary by value (as is asked in the question), one could do the following:\\nfor key, value in sorted(mydict.iteritems(), key=lambda (k,v): (v,k)):\\n    print \"%s: %s\" % (key, value)\\n\\nThe result of this command (sorting the dictionary by value) should return the following:\\nbob: 1\\nalan: 2\\ndanny: 3\\ncarl: 40\\n\\n',\n",
       " 'question': 'I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.\\nI can sort on the keys, but how can I sort based on the values?\\nNote: I have read Stack Overflow question How do I sort a list of dictionaries by values of the dictionary in Python? and probably could change my code to have a list of dictionaries, but since I do not really need a list of dictionaries I wanted to know if there is a simpler solution.\\n'}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(question=query, response=answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You\\'re a python coder. Provide concise and short python code for the question based on the context.\\nQUESTION: How to sort a dictionary in python?\\n\\nCONTEXT: \\n[\\'Why not try this approach. Let us define a dictionary called mydict with the following data:\\\\nmydict = {\\\\\\'carl\\\\\\':40,\\\\n          \\\\\\'alan\\\\\\':2,\\\\n          \\\\\\'bob\\\\\\':1,\\\\n          \\\\\\'danny\\\\\\':3}\\\\n\\\\nIf one wanted to sort the dictionary by keys, one could do something like:\\\\nfor key in sorted(mydict.iterkeys()):\\\\n    print \"%s: %s\" % (key, mydict[key])\\\\n\\\\nThis should return the following output:\\\\nalan: 2\\\\nbob: 1\\\\ncarl: 40\\\\ndanny: 3\\\\n\\\\nOn the other hand, if one wanted to sort a dictionary by value (as is asked in the question), one could do the following:\\\\nfor key, value in sorted(mydict.iteritems(), key=lambda (k,v): (v,k)):\\\\n    print \"%s: %s\" % (key, value)\\\\n\\\\nThe result of this command (sorting the dictionary by value) should return the following:\\\\nbob: 1\\\\nalan: 2\\\\ndanny: 3\\\\ncarl: 40\\\\n\\\\n\\', \\'You can use the collections.Counter. Note, this will work for both numeric and non-numeric values.\\\\n>>> x = {1: 2, 3: 4, 4:3, 2:1, 0:0}\\\\n>>> from collections import Counter\\\\n>>> #To sort in reverse order\\\\n>>> Counter(x).most_common()\\\\n[(3, 4), (4, 3), (1, 2), (2, 1), (0, 0)]\\\\n>>> #To sort in ascending order\\\\n>>> Counter(x).most_common()[::-1]\\\\n[(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)]\\\\n>>> #To get a dictionary sorted by values\\\\n>>> from collections import OrderedDict\\\\n>>> OrderedDict(Counter(x).most_common()[::-1])\\\\nOrderedDict([(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)])\\\\n\\\\n\\']\\nIf you dont know the answer, just say that you dont know.'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1591"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  148,    31,    60,     3,     9,     3,   102,    63,   189,   106,\n",
      "          1081,    52,     5,  7740, 22874,    11,   710,     3,   102,    63,\n",
      "           189,   106,  1081,    21,     8,   822,     3,   390,    30,     8,\n",
      "          2625,     5,     3, 15367,   134,  9562,    10,   571,    12,  1843,\n",
      "             3,     9, 24297,    16,     3,   102,    63,   189,   106,    58,\n",
      "          8472,  3463,     4,   382,    10,   784,    31, 17891,    59,   653,\n",
      "            48,  1295,     5,  1563,   178,  6634,     3,     9, 24297,   718,\n",
      "            82, 12194,    28,     8,   826,   331,    10,     2,    29,  2258,\n",
      "         12194,  3274,     3,     2,    31,  1720,    40,     2,    31,    10,\n",
      "          2445,     6,     2,    29,     3,     2,    31,     9,  1618,     2,\n",
      "            31,    10,  4482,     2,    29,     3,     2,    31, 17396,     2,\n",
      "            31,    10,  4347,     2,    29,     3,     2,    31,    26, 15159,\n",
      "             2,    31,    10,   519,     2,    29,     2,    29,  5801,    80,\n",
      "          1114,    12,  1843,     8, 24297,    57,  9060,     6,    80,   228,\n",
      "           103,   424,   114,    10,     2,    29,  1161,   843,    16,     3,\n",
      "         14504,   599,  2258, 12194,     5,   155,    49,  4397,     7,  9960,\n",
      "            61,    10,     2,    29,  2281,    96,  1454,     7,    10,     3,\n",
      "          1454,     7,   121,     3,  1454,    41,  4397,     6,    82, 12194,\n",
      "          6306,  4397,   908,    61,     2,    29,     2,    29,  3713,   225,\n",
      "          1205,     8,   826,  3911,    10,     2,    29,     9,  1618,    10,\n",
      "           204,     2,    29, 17396,    10,   209,     2,    29,  1720,    40,\n",
      "            10,  1283,     2,   727, 15159,    10,   220,     2,    29,     2,\n",
      "            29,  7638,     8,   119,   609,     6,     3,    99,    80,  1114,\n",
      "            12,  1843,     3,     9, 24297,    57,   701,    41,     9,     7,\n",
      "            19,  1380,    16,     8,   822,   201,    80,   228,   103,     8,\n",
      "           826,    10,     2,    29,  1161,   843,     6,   701,    16,     3,\n",
      "         14504,   599,  2258, 12194,     5,   155,    15,  5730,    51,     7,\n",
      "          9960,     6,   843,  2423,    40,   265,   115,    26,     9,    41,\n",
      "           157,     6,   208,    61,    10,    41,   208,     6,   157,    61,\n",
      "            61,    10,     2,    29,  2281,    96,  1454,     7,    10,     3,\n",
      "          1454,     7,   121,     3,  1454,    41,  4397,     6,   701,    61,\n",
      "             2,    29,     2,    29,   634,   741,    13,    48,  4106,    41,\n",
      "          9309,    53,     8, 24297,    57,   701,    61,   225,  1205,     8,\n",
      "           826,    10,     2,    29, 17396,    10,   209,     2,    29,     9,\n",
      "          1618,    10,   204,     2,   727, 15159,    10,   220,     2,    29,\n",
      "          1720,    40,    10,  1283,     2,    29,     2,    29,    31,     6,\n",
      "             3,    31,  3774,    54,   169,     8,  8274,     5, 10628,    49,\n",
      "             5,  2507,     6,    48,    56,   161,    21,   321,   206, 17552,\n",
      "            11,   529,    18,    29,    76, 17552,  2620,     5,     2,    29,\n",
      "          3155,  3155,  3155,     3,   226,  3274,     3,     2,   536,    10,\n",
      "          3547,   220,    10,  6464,   314,    10,  6355, 27078,     6,     3,\n",
      "           632,    10,   632,     2,    29,  3155,  3155,  3155,    45,  8274,\n",
      "          4830, 17706,     2,    29,  3155,  3155,  3155,  1713,  3696,  1843,\n",
      "            16,  7211,   455,     2,    29,  3155,  3155,  3155, 17706,   599,\n",
      "           226,   137,  5463,   834,   287,  2157,  9960,     2,    29,  6306,\n",
      "           599,  6355,   314,   201,  8457,     6,   220,   201,  4077,     6,\n",
      "          9266,     6,  4743,     6,  8925,     6, 17482,     6,     3,   632,\n",
      "            61,   908,     2,    29,  3155,  3155,  3155,  1713,  3696,  1843,\n",
      "            16, 25200,    53,   455,     2,    29,  3155,  3155,  3155, 17706,\n",
      "           599,   226,   137,  5463,   834,   287,  2157,  9960,  6306,    10,\n",
      "            10,  2292,   908,     2,    29,  6306,   599,   632,     6,     3,\n",
      "           632,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True, padding='max_length')\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     3, 15367,   134,  9562,    10,   784,    31, 17891,    59,\n",
      "           653,    48,  1295,     5,  1563,   178,  6634,     3,     9, 24297,\n",
      "           718,    82, 12194,    28,     8,   826,   331,    10,     2,    29,\n",
      "          2258, 12194,  3274,     3,     2,    31,  1720,    40,     2,    31,\n",
      "            10,  2445,     6,     2,    29,     3,     2,    31,     9,  1618,\n",
      "             2,    31,    10,  4482,     2,    29,     3,     2,    31, 17396,\n",
      "             2,    31,    10,  4347,     2,    29,     3,     2,    31,    26,\n",
      "         15159,     2,    31,    10,   519,     2,    29,     2,    29,   634,\n",
      "           741,    13,    48,  4106,    41,  9309,    53,     8, 24297,    57,\n",
      "           701,    61,   225,  1205,     8,   826,  3911,    10,     2,    29,\n",
      "         17396,    10,   209,     2,    29,     9,  1618,    10,   204,     2,\n",
      "           727, 15159,    10,   220,     1]])\n",
      "QUESTION: ['Why not try this approach. Let us define a dictionary called mydict with the following data:nmydict = 'carl':40,n 'alan':2,n 'bob':1,n 'danny':3nnThe result of this command (sorting the dictionary by value) should return the following output:nbob: 1nalan: 2ndanny: 3\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    inputs['input_ids'], \n",
    "    max_length=150, \n",
    "    num_beams=4, \n",
    "    # early_stopping=True\n",
    ")\n",
    "print(outputs)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling longer chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retreiving\n",
    "# Indexing - Elasticsearch, TF-IDF \n",
    "# Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import minisearch\n",
    "\n",
    "\n",
    "ms = minisearch.Index(\n",
    "    text_fields=[\"Response\"],\n",
    "    keyword_fields=[\"Context\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minisearch.Index at 0x1a9a25371c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.fit(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text, max_length=512):\n",
    "    # Split text into chunks of max_length tokens\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\")['input_ids'][0]\n",
    "    chunks = [tokens[i:i+max_length] for i in range(0, len(tokens), max_length)]\n",
    "    return chunks\n",
    "\n",
    "# Split long text\n",
    "text_chunks = split_text(long_text)\n",
    "\n",
    "# Generate output for each chunk\n",
    "results = []\n",
    "for chunk in text_chunks:\n",
    "    inputs = tokenizer.decode(chunk, return_tensors=\"pt\").unsqueeze(0)\n",
    "    outputs = model.generate(inputs['input_ids'], max_length=150, num_beams=4, early_stopping=True)\n",
    "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    results.append(decoded_output)\n",
    "\n",
    "# Combine results if necessary\n",
    "combined_output = ' '.join(results)\n",
    "print(combined_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
