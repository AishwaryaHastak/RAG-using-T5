{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Ground Truth Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add IDs to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Read data into dataframe \n",
    "df = pd.read_csv(\"data/topic_data.csv\").dropna()\n",
    "\n",
    "# Convert dataframe to list of dictionaries\n",
    "data_dict = df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def generate_document_id(doc):\n",
    "    # combined = f\"{doc['course']}-{doc['question']}\"\n",
    "    combined = f\"{doc['answer']}-{doc['question']}\"\n",
    "    hash_object = hashlib.md5(combined.encode())\n",
    "    hash_hex = hash_object.hexdigest()\n",
    "    document_id = hash_hex[:8]\n",
    "    return document_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in data_dict:\n",
    "    doc['id'] = generate_document_id(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check unique document ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "hash = defaultdict(list)\n",
    "for doc in data_dict:\n",
    "    hash[doc['id']].append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639 598\n"
     ]
    }
   ],
   "source": [
    "print(len(data_dict), len(hash))\n",
    "duplicate_ids =[]\n",
    "for k,values in hash.items():\n",
    "    if len(values)>1:\n",
    "        duplicate_ids.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "print(len(duplicate_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = pd.read_csv('data/ground_truth.csv',usecols=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>document_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the main considerations in balancing ...</td>\n",
       "      <td>08aa7d88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the bias-variance trade-off affect mo...</td>\n",
       "      <td>08aa7d88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What strategies can be employed to manage bias...</td>\n",
       "      <td>08aa7d88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question document_id\n",
       "0  What are the main considerations in balancing ...    08aa7d88\n",
       "1  How does the bias-variance trade-off affect mo...    08aa7d88\n",
       "2  What strategies can be employed to manage bias...    08aa7d88"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df_duplicate = gt_df[gt_df['document_id'].isin(duplicate_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>document_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [question, document_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_df_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def generate_topic(doc):\n",
    "#     topic_mapping = {'Supervised Learning': 'Supervised Learning',\n",
    "#                      'RAG': 'RAG',\n",
    "#                      'Unsupervised Learning KNN': 'Unsupervised Learning',\n",
    "#                      'LLM': 'LLM',\n",
    "#                      'Evaluation metrics': 'Model Evaluation',\n",
    "#                 'Recommend matrix factoqrization': 'Recommender Systems',}\n",
    "#     if doc['answer'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '94727dd0',\n",
       " 'question': 'How would you evaluate a logistic regression model?',\n",
       " 'answer': \"To evaluate a logistic regression model, use the confusion matrix to analyze true positives, true negatives, false positives, and false negatives. Accuracy measures the proportion of correct predictions, while precision and recall are critical when false positives or false negatives have significant implications. Additionally, the ROC curve and AUC (Area Under the Curve) assess the model's ability to distinguish between classes across various thresholds. Logistic Regression is often used for binary classification and these metrics help in understanding its performance comprehensively.\",\n",
       " 'topic': 'Model Evaluation'}"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(data_dict)\n",
    "# Set 'id' column as the index\n",
    "new_df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34a96b07</th>\n",
       "      <td>When should you use classification over regres...</td>\n",
       "      <td>Use classification when you need to categorize...</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075cd3f</th>\n",
       "      <td>Name an example where ensemble techniques migh...</td>\n",
       "      <td>Ensemble techniques, like bagging and boosting...</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10e5ca34</th>\n",
       "      <td>How do you ensure you’re not overfitting with ...</td>\n",
       "      <td>To avoid overfitting, you can: 1) Simplify the...</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   question  \\\n",
       "id                                                            \n",
       "34a96b07  When should you use classification over regres...   \n",
       "2075cd3f  Name an example where ensemble techniques migh...   \n",
       "10e5ca34  How do you ensure you’re not overfitting with ...   \n",
       "\n",
       "                                                     answer         topic  \n",
       "id                                                                         \n",
       "34a96b07  Use classification when you need to categorize...  Data Science  \n",
       "2075cd3f  Ensemble techniques, like bagging and boosting...  Data Science  \n",
       "10e5ca34  To avoid overfitting, you can: 1) Simplify the...  Data Science  "
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write to new .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commenting the line below to prevent overwriting of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df.to_csv('data/ml_indexed.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '2075cd3f',\n",
       " 'question': 'Name an example where ensemble techniques might be useful.',\n",
       " 'answer': 'Ensemble techniques, like bagging and boosting, combine multiple models to improve predictive performance and robustness. For example, in a classification task, using a Random Forest (which combines multiple decision trees) can reduce overfitting and enhance accuracy compared to a single decision tree.',\n",
       " 'topic': 'Data Science'}"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add topic column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read data into dataframe \n",
    "df = pd.read_csv(\"data/ml_indexed.csv\").dropna()\n",
    "\n",
    "# Convert dataframe to list of dictionaries\n",
    "data_dict = df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_mapping = {\n",
    "    'Supervised Learning': 'Supervised Learning',\n",
    "    'RAG retrieval': 'RAG',\n",
    "    'Unsupervised  KNN kNN clustering': 'Unsupervised Learning',\n",
    "    'LLM language': 'LLM',\n",
    "    'PCA feature engineering': 'Feature Engineering',\n",
    "    'metrics evaluation evaluate ROC AUC': 'Model Evaluation',\n",
    "    'tuning hyperparameter MLFlow': 'Model Tuning',\n",
    "    'deploy deployment production': 'Model Deployment',\n",
    "    'Adverserial': 'GAN',\n",
    "    'Recommend matrix factorization': 'Recommender Systems',\n",
    "}\n",
    "\n",
    "# Function to check if any word in the key is in the text\n",
    "def contains_any_word(text, words):\n",
    "    text = text.lower()\n",
    "    for word in words:\n",
    "        if word.lower() in text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "for row in data_dict:\n",
    "    # Initialize 'topic' to default value\n",
    "    row['topic'] = 'Data Science'\n",
    "    \n",
    "    # Check if any key in topic_mapping appears in 'question' or 'answer'\n",
    "    for key, value in topic_mapping.items():\n",
    "        key_words = key.split()  # Tokenize the key into words\n",
    "        if (contains_any_word(row.get('question', ''), key_words) or \n",
    "            contains_any_word(row.get('answer', ''), key_words)):\n",
    "            row['topic'] = value\n",
    "            break  # Stop checking once a match is found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "Supervised Learning      222\n",
       "Model Evaluation         110\n",
       "Feature Engineering       94\n",
       "RAG                       73\n",
       "Data Science              62\n",
       "Unsupervised Learning     30\n",
       "LLM                       23\n",
       "Recommender Systems       13\n",
       "Model Tuning               8\n",
       "Model Deployment           4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df = pd.DataFrame(data_dict)\n",
    "topic_df['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df.to_csv('data/topic_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Evalition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create index on documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data into dataframe \n",
    "df = pd.read_csv(\"data/topic_data.csv\").dropna()\n",
    "\n",
    "# Convert dataframe to list of dictionaries\n",
    "data_dict = df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 384 #128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "index_settings={\n",
    "    \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "        \"question\": {\"type\": \"text\"},\n",
    "        \"answer\": {\"type\": \"text\"},\n",
    "        \"topic\": {\"type\": \"keyword\"},\n",
    "        \"id\": {\"type\": \"keyword\"},\n",
    "        \"answer_vector\": {\"type\": \"dense_vector\", \"dims\": embedding_size, \"index\": True, \"similarity\": \"cosine\"},\n",
    "        \"question_vector\": {\"type\": \"dense_vector\", \"dims\": embedding_size, \"index\": True, \"similarity\": \"cosine\"},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "index_name = 'python-qa-index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'python-qa-index'})"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.delete(index=index_name,ignore_unavailable=True)\n",
    "es.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 639/639 [00:37<00:00, 16.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Add Data to Index using index()\n",
    "for i in tqdm(range(len(data_dict))):\n",
    "    row = data_dict[i]\n",
    "    es.index(index=index_name, id=i, document=row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define elastic search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"answer\", \"topic\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = es.search(index=index_name, body=search_query)\n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ground_truth = pd.read_csv('data/ground_truth.csv', header = 0, usecols=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1735 {'question': 'When is it appropriate to use classification rather than regression?', 'document_id': '34a96b07'}\n"
     ]
    }
   ],
   "source": [
    "print(len(ground_truth), ground_truth[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1735/1735 [02:01<00:00, 14.25it/s]\n"
     ]
    }
   ],
   "source": [
    "relevance_total = []\n",
    "\n",
    "for q in tqdm(ground_truth):\n",
    "    doc_id = q['document_id']\n",
    "    results = elastic_search(query=q['question'])\n",
    "    relevance = [d['id'] == doc_id for d in results]\n",
    "    relevance_total.append(relevance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calucalte hit rate and mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.768299711815562, 0.706484149855908)"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(hit_rate(relevance_total), mrr(relevance_total)) # question3, answer3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elastic Search \n",
    "```\n",
    "(0.768299711815562, 0.706484149855908)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using minisearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minisearch.Index at 0x261962768e0>"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minisearch\n",
    "ms = minisearch.Index(\n",
    "    text_fields=['question', 'answer'],\n",
    "    keyword_fields=['topic','id'],\n",
    ")\n",
    "\n",
    "ms.fit(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_search(query):\n",
    "    results = ms.search( query = query,\n",
    "                    num_results = 5)\n",
    "    # response = [result['answer'] for result in results]\n",
    "    # return response\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1735/1735 [00:03<00:00, 515.55it/s]\n"
     ]
    }
   ],
   "source": [
    "relevance_total = []\n",
    "\n",
    "for q in tqdm(ground_truth):\n",
    "    doc_id = q['document_id']\n",
    "    results = mini_search(query=q['question'])\n",
    "    relevance = [d['id'] == doc_id for d in results]\n",
    "    relevance_total.append(relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8242074927953891, 0.7583669548511048)"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(hit_rate(relevance_total), mrr(relevance_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minisearch \n",
    "```\n",
    "(0.8242074927953891, 0.7583669548511048)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "embedding_size = 384 \n",
    "model = SentenceTransformer(model_name)#, truncate_dim=embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'python-qa-index'})"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings={\n",
    "    \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "        \"question\": {\"type\": \"text\"},\n",
    "        \"answer\": {\"type\": \"text\"},\n",
    "        \"topic\": {\"type\": \"keyword\"},\n",
    "        \"id\": {\"type\": \"keyword\"},\n",
    "        \"answer_vector\": {\"type\": \"dense_vector\", \"dims\": embedding_size, \"index\": True, \"similarity\": \"cosine\"},\n",
    "        \"question_vector\": {\"type\": \"dense_vector\", \"dims\": embedding_size, \"index\": True, \"similarity\": \"cosine\"},\n",
    "        \"question_answer_vector\": {\"type\": \"dense_vector\", \"dims\": embedding_size, \"index\": True, \"similarity\": \"cosine\"},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create Index and delete if it already exists\n",
    "es.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es.indices.create(index=index_name, body = index_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding the answer and query vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 639/639 [02:08<00:00,  4.97it/s]\n"
     ]
    }
   ],
   "source": [
    "vector_data_dict = []\n",
    "for i in tqdm(data_dict):\n",
    "    question_answer = i['question'] + ' ' + i['answer']\n",
    "    i['answer_vector'] = model.encode(i['answer'])\n",
    "    i['question_vector'] = model.encode(i['question'])\n",
    "    i['question_answer_vector'] = model.encode(question_answer)\n",
    "    vector_data_dict.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating index on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[[DEBUG] Adding data to index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 639/639 [00:41<00:00, 15.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Add Data to Index using index()\n",
    "print('\\n\\n[[DEBUG] Adding data to index...')\n",
    "for i in tqdm(vector_data_dict):\n",
    "    row = i\n",
    "    es.index(index=index_name, document=row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': '7d50c3ad219e', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'GkHNY1cCQQGIGcngnIggvA', 'version': {'number': '8.15.0', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '1a77947f34deddb41af25e6f0ddb8e830159c179', 'build_date': '2024-08-05T10:05:34.233336849Z', 'build_snapshot': False, 'lucene_version': '9.11.1', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "print(es.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn(field, vector):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "    }\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"answer\", \"question\", \"topic\", \"id\"]\n",
    "    }\n",
    "    es_results = es.search(\n",
    "        index=index_name, \n",
    "        body=search_query\n",
    "    )\n",
    "    result_docs = []\n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_vector_knn(q):\n",
    "    question = q['question'] \n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('question_vector', v_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document_id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance) \n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1735/1735 [02:26<00:00, 11.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.8582132564841498, 'mrr': 0.8392699327569638}"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, question_vector_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_vector_knn(q):\n",
    "    question = q['question'] \n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('answer_vector', v_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document_id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1735/1735 [02:29<00:00, 11.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.8553314121037464, 'mrr': 0.810528338136407}"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, answer_vector_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question-Answer vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer_vector_knn(q):\n",
    "    question = q['question'] \n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('question_answer_vector', v_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document_id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1735/1735 [03:00<00:00,  9.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.8795389048991354, 'mrr': 0.8574159462055707}"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, question_answer_vector_knn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
